<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">

<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
    <head>
        <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
        <title>Houwen Peng's Homepage</title>
        
            
        <!-- CSS -->
        <link href="css" rel="stylesheet" type="text/css">
        <link rel="stylesheet" href="style.css" type="text/css" media="screen">
        <!-- ENDS CSS -->
        <script src="http://ajax.googleapis.com/ajax/libs/jquery/1.10.2/jquery.min.js"></script>
        <link rel="shortcut icon" href="./icon/ms.ico">
        <!-- ENDS JS -->  
    </head> 
    <body>
        <!-- MAIN -->
        <div id="">
           <div id="match-nav-wrapper">
               <div id="match-nav-bar">
                     <table>
                        <thead>
                            <tr valign="bottom">
                                <th width="" style="font-size: 25px;  color: #00A4EF"></th>
                                <th width=55% ></th>
                                <th width=""><a href="index.html">Homepage</a> </th>
                                <th width=""><a href="publication.html">Research</a></th>
                                <th width=""><a href="group.html">Subgroup</a></th>
                            </tr>
                        </thead>
                    </table>
                </div>
            </div>
            <!-- HEADER -->


            <div id="main-wrapper">

                <div id="portfolio-info">
                <h1> Publications</h1>
                    <hr2/>
                    <!--
                    </br>
                    <div class="line"></div>
                    <div style="display:inline-block;"><strong>2020</strong></div>
                    <div class="line"></div>
                    -->

                <!-- <br><strong><font face="Arial" size="4">  &nbsp &nbsp 2020 </font> </strong> </br>     -->
                    <table id="portfolio-projects">
                        

                        <tbody>

                        <tr style="border-width: 1px">
                            <td><img src="./publications/Xwin-Math.png" style="margin-bottom: 0px"></td>
                            <td style="">
                                <table style="width: 100%;"><tbody><tr><td style="width: 100%; text-align: left;">
                                <p>
                                    <b>Common 7B Language Models Already Possess Strong Math Capabilities</b><br>
                                   
                                    <div class="authors">
                                      <span class="author me">Chen Li</span>,
                                      <span class="author me">Weiqi Wang</span>,
                                      <span class="author me">Jingcheng Hu</span>,
                                      <span class="author"><a href="https://scholar.google.com/citations?user=xwudKb4AAAAJ&hl=en&oi=ao">Yixuan Wei</a></span>,
                                      <span class="author me">Nanning Zheng</span>,
                                      <span class="author"><a href="https://ancientmooner.github.io/">Han Hu</a></span>,
                                      <span class="author"><a href="https://stupidzz.github.io/">Zheng Zhang</a></span>,
                                      <span class="author me">Houwen Peng</span>
                                    </div>
                                    <div>
                                      <span class="venue"><a href="https://arxiv.org/abs/2403.04706">Tech Report</a> /
                                      <span class="tag"><a href="https://github.com/Xwin-LM/Xwin-LM">Code</a></span>
                                    <br>
                                    </div>
                                </p>
                                </td><td style="width: 10px;">
                                </td>
                                </tr>
                                </tbody></table>           
                            </td>
                        </tr> 

                        <tr style="border-width: 1px">
                            <td><img src="./publications/FP8-LM.png" style="margin-bottom: 0px"></td>
                            <td style="">
                                <table style="width: 100%;"><tbody><tr><td style="width: 100%; text-align: left;">
                                <p>
                                    <b>FP8-LM: Training FP8 Large Language Models</b><br>
                                   
                                    <div class="authors">
                                      <span class="author me">Houwen Peng</span>,
                                      <span class="author"><a href="https://scholar.google.com/citations?user=sK4JUL4AAAAJ&hl=zh-CN&oi=sra">Kan Wu</a></span>,
                                      <span class="author"><a href="https://scholar.google.com/citations?user=xwudKb4AAAAJ&hl=en&oi=ao">Yixuan Wei</a></span>,
                                      <span class="author me">Guoshuai Zhao</span>,
                                      <span class="author me">Yuxiang Yang</span>,
                                      <span class="author"><a href="https://zeliu98.github.io/">Ze Liu</a></span>,
                                      <span class="author me">Yifan Xiong</span>,
                                      <span class="author me">Ziyue Yang</span>,
                                      <span class="author me">Bolin Ni</span>,
                                      <span class="author me">Jingcheng Hu</span>,
                                      <span class="author me">Ruihang Li</span>,
                                      <span class="author me">Chen Li</span>,
                                      <span class="author me">Jia Ning</span>,
                                      <span class="author me">Ruizhe Wang</span>,
                                      <span class="author"><a href="https://stupidzz.github.io/">Zheng Zhang</a></span>,
                                      <span class="author me">Shuguang Liu</span>,
                                      <span class="author"><a href="https://ancientmooner.github.io/">Han Hu</a></span>,
                                      <span class="author"><a href="https://www.microsoft.com/en-us/research/people/pengc/">Peng Cheng</a></span>
                                    </div>
                                    <div>
                                      <span class="venue"><a href="https://arxiv.org/abs/2310.18313">Tech Report</a> /
                                      <span class="tag"><a href="https://github.com/Azure/MS-AMP">Code</a></span>
                                    <br>
                                    </div>
                                </p>
                                </td><td style="width: 10px;">
                                </td>
                                </tr>
                                </tbody></table>           
                            </td>
                        </tr> 


                        <tr style="border-width: 1px">
                            <td><img src="./publications/ImageBrush.png" style="margin-bottom: 0px"></td>
                            <td style="">
                                <table style="width: 100%;"><tbody><tr><td style="width: 100%; text-align: left;">
                                <p>
                                    <b>ImageBrush: Learning Visual In-Context Instructions for Exemplar-Based Image Manipulation</b><br>
                                   
                                    <div class="authors">
                                      <span class="author"><a href="">Yasheng Sun</a></span>,
                                      <span class="author"><a href="">Yifan Yang</a></span>,
                                      <span class="author me">Houwen Peng*</span>,
                                      <span class="author"><a href="">Yifei Shen</a></span>,
                                      <span class="author"><a href="">Yuqing Yang</a></span>,
                                      <span class="author"><a href="https://ancientmooner.github.io/">Han Hu</a></span>,
                                      <span class="author"><a href="https://scholar.google.com/citations?user=16posrQAAAAJ&hl=en&oi=ao/">Lili Qiu</a></span>,
                                      <span class="author"><a href="">Hideki Koike</a></span>
                                    </div>
                                    <div>
                                      <span class="venue"><a href="https://nips.cc/">NeurIPS 2023</a> /
                                      <span class="tag"><a href="https://arxiv.org/abs/2308.00906">Paper</a></span> / 
                                      <span class="tag"><a href="">Coming</a></span> 
                                    <br>
                                    </div>
                                </p>
                                </td><td style="width: 10px;">
                                </td>
                                </tr>
                                </tbody></table>           
                            </td>
                        </tr> 


                        <tr style="border-width: 1px">
                            <td><img src="./publications/TinyCLIP.png" style="margin-bottom: 0px"></td>
                            <td style="">
                                <table style="width: 100%;"><tbody><tr><td style="width: 100%; text-align: left;">
                                <p>
                                    <b>TinyCLIP: CLIP Distillation via Affinity Mimicking and Weight Inheritance</b><br>
                                   
                                    <div class="authors">
                                      <span class="author"><a href="https://scholar.google.com/citations?user=sK4JUL4AAAAJ&hl=zh-CN&oi=sra">Kan Wu</a></span>,
                                      <span class="author me">Houwen Peng*</span>,
                                      <span class="author"><a href="">Zhenghong Zhou</a></span>,
                                      <span class="author"><a href="https://www.microsoft.com/en-us/research/people/bixi/">Bin Xiao</a></span>,
                                      <span class="author"><a href="https://scholar.google.com/citations?user=cOPQtYgAAAAJ&hl=zh-CN&oi=ao">Mengchen Liu</a></span>,
                                      <span class="author"><a href="https://www.microsoft.com/en-us/research/people/luyuan/">Lu Yuan</a></span>,
                                      <span class="author"><a href="">Hong Xuan</a></span>,
                                      <span class="author"><a href="">Zhenghong Zhou</a></span>,
                                      <span class="author"><a href="">Xi Chen</a></span>,
                                      <span class="author"><a href="https://xwcv.github.io/">Xinggang Wang</a></span>,
                                      <span class="author">Hongyang Chao</span>,
                                      <span class="author"><a href="https://ancientmooner.github.io/">Han Hu</a></span>
                                    </div>
                                    <div>
                                      <span class="venue"><a href="https://openaccess.thecvf.com/ICCV2023?day=all">ICCV 2023</a> /
                                      <span class="tag"><a href="https://openaccess.thecvf.com/content/ICCV2023/papers/Wu_TinyCLIP_CLIP_Distillation_via_Affinity_Mimicking_and_Weight_Inheritance_ICCV_2023_paper.pdf">Paper</a></span> / 
                                      <span class="tag"><a href="https://github.com/microsoft/Cream">Code</a></span> 
                                    <br>
                                    </div>
                                </p>
                                </td><td style="width: 10px;">
                                </td>
                                </tr>
                                </tbody></table>           
                            </td>
                        </tr> 


                        <tr style="border-width: 1px">
                            <td><img src="./publications/A-CLIP.png" style="margin-bottom: 0px"></td>
                            <td style="">
                                <table style="width: 100%;"><tbody><tr><td style="width: 100%; text-align: left;">
                                <p>
                                    <b>Attentive Mask CLIP</b><br>
                                   
                                    <div class="authors">
                                      <span class="author"><a href="">Yifan Yang</a></span>,
                                      <span class="author"><a href="">Weiquan Huang</a></span>,
                                      <span class="author"><a href="https://scholar.google.com/citations?user=xwudKb4AAAAJ&hl=en&oi=ao">Yixuan Wei</a></span>,
                                      <span class="author me">Houwen Peng*</span>,
                                      <span class="author"><a href="">Xinyang Jiang</a></span>,
                                      <span class="author"><a href="">Huiqiang Jiang</a></span>,
                                      <span class="author"><a href="">Fangyun Wei</a></span>,
                                      <span class="author"><a href="">Yin Wang</a></span>,
                                      <span class="author"><a href="https://ancientmooner.github.io/">Han Hu</a></span>
                                      <span class="author"><a href="https://scholar.google.com/citations?user=16posrQAAAAJ&hl=en&oi=ao/">Lili Qiu</a></span>
                                      <span class="author"><a href="">Yuqing Yang</a></span>
                                    </div>
                                    <div>
                                      <span class="venue"><a href="https://openaccess.thecvf.com/ICCV2023?day=all">ICCV 2023</a> /
                                      <span class="tag"><a href="https://openaccess.thecvf.com/content/ICCV2023/papers/Yang_Attentive_Mask_CLIP_ICCV_2023_paper.pdf">Paper</a></span> / 
                                      <span class="tag"><a href="https://github.com/microsoft/A-CLIP">Code</a></span> 
                                    <br>
                                    </div>
                                </p>
                                </td><td style="width: 10px;">
                                </td>
                                </tr>
                                </tbody></table>           
                            </td>
                        </tr> 


                        <tr style="border-width: 1px">
                            <td><img src="./publications/HIT.png" style="margin-bottom: 0px"></td>
                            <td style="">
                                <table style="width: 100%;"><tbody><tr><td style="width: 100%; text-align: left;">
                                <p>
                                    <b>Exploring Lightweight Hierarchical Vision Transformers for Efficient Visual Tracking</b><br>
                                   
                                    <div class="authors">
                                      <span class="author"><a href="">Ben Kang</a></span>,
                                      <span class="author"><a href="">Xin Chen</a></span>,
                                      <span class="author"><a href="https://scholar.google.com/citations?user=nVgPQpoAAAAJ&hl=ja&oi=ao">Dong Wang</a></span>,
                                      <span class="author me">Houwen Peng*</span>,
                                      <span class="author"><a href="http://ice.dlut.edu.cn/lu/index.html">Huchuan Lu</a></span>
                                    </div>
                                    <div>
                                      <span class="venue"><a href="https://openaccess.thecvf.com/ICCV2023?day=all">ICCV 2023</a> /
                                      <span class="tag"><a href="https://openaccess.thecvf.com/content/ICCV2023/papers/Kang_Exploring_Lightweight_Hierarchical_Vision_Transformers_for_Efficient_Visual_Tracking_ICCV_2023_paper.pdf">Paper</a></span> / 
                                      <span class="tag"><a href="https://github.com/kangben258/HiT">Code</a></span> 
                                    <br>
                                    </div>
                                </p>
                                </td><td style="width: 10px;">
                                </td>
                                </tr>
                                </tbody></table>           
                            </td>
                        </tr> 


                         <tr style="border-width: 1px">
                            <td><img src="./publications/EfficientVit.gif" style="margin-bottom: 0px"></td>
                            <td style="">
                                <table style="width: 100%;"><tbody><tr><td style="width: 100%; text-align: left;">
                                <p>
                                    <b>EfficientViT: Memory Efficient Vision Transformer with Cascaded Group Attention</b><br>
                                   
                                    <div class="authors">
                                      
                                      <span class="author"><a href="https://xinyuliu-jeffrey.github.io/">Xinyu Liu</a></span>,
                                      <span class="author me">Houwen Peng*</span>,
                                      <span class="author"><a href="">Ningxin Zheng</a></span>,
                                      <span class="author"><a href="">Yuqing Yang</a></span>,
                                      <span class="author"><a href="https://ancientmooner.github.io/">Han Hu</a></span>,
                                      <span class="author"><a href="http://www.ee.cuhk.edu.hk/~yxyuan/">Yixuan Yuan</a></span>
                                    </div>
                                    <div>
                                      <span class="venue"><a href="https://openaccess.thecvf.com/CVPR2023?day=all">CVPR 2023</a> /
                                      <span class="tag"><a href="https://openaccess.thecvf.com/content/CVPR2023/papers/Liu_EfficientViT_Memory_Efficient_Vision_Transformer_With_Cascaded_Group_Attention_CVPR_2023_paper.pdf">Paper</a></span> / 
                                      <span class="tag"><a href="https://github.com/microsoft/Cream/tree/main/EfficientViT">Code</a></span> 
                                    <br>
                                    </div>
                                </p>
                                </td><td style="width: 10px;">
                                </td>
                                </tr>
                                </tbody></table>           
                            </td>
                        </tr> 

                        <tr style="border-width: 1px">
                            <td><img src="./publications/SeqTrack.png" style="margin-bottom: 0px"></td>
                            <td style="">
                                <table style="width: 100%;"><tbody><tr><td style="width: 100%; text-align: left;">
                                <p>
                                    <b>SeqTrack: Sequence to Sequence Learning for Visual Object Tracking</b><br>
                                   
                                    <div class="authors">
                                      
                                      <span class="author"><a href="">Xin Chen</a></span>,
                                      <span class="author me">Houwen Peng*</span>,
                                      <span class="author"><a href="https://scholar.google.com/citations?user=nVgPQpoAAAAJ&hl=ja&oi=ao">Dong Wang</a></span>,
                                      <span class="author"><a href="http://ice.dlut.edu.cn/lu/index.html">Huchuan Lu</a></span>,
                                      <span class="author"><a href="https://ancientmooner.github.io/">Han Hu</a></span>
                                    </div>
                                    <div>
                                      <span class="venue"><a href="https://openaccess.thecvf.com/CVPR2023?day=all">CVPR 2023</a> /
                                      <span class="tag"><a href="https://openaccess.thecvf.com/content/CVPR2023/papers/Chen_SeqTrack_Sequence_to_Sequence_Learning_for_Visual_Object_Tracking_CVPR_2023_paper.pdf">Paper</a></span> / 
                                      <span class="tag"><a href="https://github.com/microsoft/VideoX">Code</a></span> 
                                    <br>
                                    </div>
                                </p>
                                </td><td style="width: 10px;">
                                </td>
                                </tr>
                                </tbody></table>           
                            </td>
                        </tr> 



                        <tr style="border-width: 1px">
                            <td><img src="./publications/iCLIP.png" style="margin-bottom: 0px"></td>
                            <td style="">
                                <table style="width: 100%;"><tbody><tr><td style="width: 100%; text-align: left;">
                                <p>
                                    <b>iCLIP: Bridging Image Classification and Contrastive Language-Image Pre-Training for Visual Recognition</b><br>
                                   
                                    <div class="authors">
                                      <span class="author"><a href="https://scholar.google.com/citations?user=xwudKb4AAAAJ&hl=en&oi=ao">Yixuan Wei</a></span>,
                                      <span class="author"><a href="http://yue-cao.me/"></a>Yue Cao</span>,
                                      <span class="author"><a href="https://stupidzz.github.io/">Zheng Zhang</a></span>,
                                      <span class="author me">Houwen Peng</span>,
                                      <span class="author"><a href="">Zhuliang Yao</a></span>,
                                      <span class="author"><a href="https://zdaxie.github.io/">Zhenda Xie</a></span>,
                                      <span class="author"><a href="https://ancientmooner.github.io/">Han Hu</a></span>,
                                      <span class="author"><a href="https://www.microsoft.com/en-us/research/people/bainguo/">Baining Guo</a></span>
                                    </div>
                                    <div>
                                      <span class="venue"><a href="https://openaccess.thecvf.com/CVPR2023?day=all">CVPR 2023</a> /
                                      <span class="tag"><a href="https://openaccess.thecvf.com/content/CVPR2023/papers/Wei_iCLIP_Bridging_Image_Classification_and_Contrastive_Language-Image_Pre-Training_for_Visual_CVPR_2023_paper.pdf">Paper</a></span> 
                                    <br>
                                    </div>
                                </p>
                                </td><td style="width: 10px;">
                                </td>
                                </tr>
                                </tbody></table>           
                            </td>
                        </tr> 


                        <tr style="border-width: 1px">
                            <td><img src="./publications/PointNeXt.png" style="margin-bottom: 0px"></td>
                            <td style="">
                                <table style="width: 100%;"><tbody><tr><td style="width: 100%; text-align: left;">
                                <p>
                                    <b>PointNeXt: Revisiting PointNet++ with Improved Training and Scaling Strategies</b><br>
                                   
                                    <div class="authors">
                                      
                                      <span class="author"><a href="">Guocheng Qian</a></span>,
                                      <span class="author"><a href="">Yuchen Li</a></span>,
                                      <span class="author me">Houwen Peng*</span>,
                                      <span class="author"><a href="">Jinjie Mai</a></span>,
                                      <span class="author"><a href="./"> Hasan Abed Al Kader Hammoud</a></span>,
                                      <span class="author"><a href="https://people.ucas.edu.cn/~gfmeng?language=en"> Mohamed Elhoseiny</a></span>,
                                      <span class="author"><a href="https://jianlong-fu.github.io/">Mohamed Elhoseiny</a></span>,
                                      <span class="author"><a href="https://people.ucas.ac.cn/~xiangshiming">Bernard Ghanem*</a></span>
                                    </div>
                                    <div>
                                      <span class="venue"><a href="https://eccv2022.ecva.net/">NeurIPS 2022</a> /
                                      <span class="tag"><a href="https://arxiv.org/pdf/2206.04670.pdf">Paper</a></span> / 
                                      <span class="tag"><a href="https://github.com/guochengqian/pointnext">Code</a></span> 
                                    <br>
                                    </div>
                                </p>
                                </td><td style="width: 10px;">
                                </td>
                                </tr>
                                </tbody></table>           
                            </td>
                        </tr> 

                        <tr style="border-width: 1px">
                            <td><img src="./publications/X-CLIP.PNG" style="margin-bottom: 0px"></td>
                            <td style="">
                                <table style="width: 100%;"><tbody><tr><td style="width: 100%; text-align: left;">
                                <p>
                                    <b>Expanding Language-Image Pretrained Models for General Video Recognition</b><br>
                                   
                                    <div class="authors">
                                      
                                      <span class="author"><a href="">Bolin Ni</a></span>,
                                      <span class="author me">Houwen Peng*</span>,
                                      <span class="author"><a href="">Minghao Chen</a></span>,
                                      <span class="author"><a href="https://sy-zhang.github.io/">Songyang Zhang</a></span>,
                                      <span class="author"><a href="https://people.ucas.edu.cn/~gfmeng?language=en">Gaofeng Meng</a></span>,
                                      <span class="author"><a href="https://jianlong-fu.github.io/">Jianlong Fu</a></span>,
                                      <span class="author"><a href="https://people.ucas.ac.cn/~xiangshiming">Shiming Xiang</a></span>,
                                      <span class="author"><a href="https://www3.cs.stonybrook.edu/~hling/">Haibin Ling</a></span>
                                    </div>
                                    <div>
                                      <span class="venue"><a href="https://eccv2022.ecva.net/">ECCV 2022</a> <span class="highlight"><a href="">Oral Presentation</a></span> </span> /
                                      <span class="tag"><a href="https://arxiv.org/pdf/2208.02816.pdf">Paper</a></span> / 
                                      <span class="tag"><a href="https://aka.ms/X-CLIP">Code</a></span> /
                                      <span class="tag"><a href="https://huggingface.co/docs/transformers/model_doc/xclip"> 🤗 Hugging Face</a></span>
                                    <br>
                                      <br>
                                    </div>
                                </p>
                                </td><td style="width: 10px;">
                                </td>
                                </tr>
                                </tbody></table>           
                            </td>
                        </tr> 

                        <tr style="border-width: 1px">
                            <td><img src="./publications/TinyViT2.png" style="margin-bottom: 0px"></td>
                            <td style="">
                                <table style="width: 100%;"><tbody><tr><td style="width: 100%; text-align: left;">
                                <p>
                                    <b>TinyViT: Fast Pretraining Distillation for Small Vision Transformers
</b><br>
                                   
                                    <div class="authors">
                                      <span class="author"><a href="https://scholar.google.com/citations?user=sK4JUL4AAAAJ&hl=zh-CN&oi=sra">Kan Wu</a></span>,
                                      <span class="author"><a href="https://scholar.google.com/citations?user=tbd4Tf4AAAAJ&hl=zh-CN&oi=ao">Jinnian Zhang</a></span>,
                                      <span class="author me">Houwen Peng*</span>,
                                      <span class="author"><a href="https://scholar.google.com/citations?user=cOPQtYgAAAAJ&hl=zh-CN&oi=ao">Mengchen Liu</a></span>,
                                      <span class="author"><a href="https://www.microsoft.com/en-us/research/people/bixi/">Bin Xiao</a></span>,
                                      <span class="author"><a href="https://jianlong-fu.github.io/">Jianlong Fu</a></span>,
                                      <span class="author"><a href="https://www.microsoft.com/en-us/research/people/luyuan/">Lu Yuan</a></span>
                                    </div>
                                    <div>
                                      <span class="venue"><a href="https://eccv2022.ecva.net/">ECCV 2022</a> </span> /
                                      <span class="tag"><a href="https://arxiv.org/pdf/2207.10666.pdf">Paper</a></span> / 
                                      <span class="tag"><a href="https://github.com/microsoft/Cream/tree/main/TinyViT">Code</a></span>
                                    <br>
                                      <br>
                                    </div>
                                </p>
                                </td><td style="width: 10px;">
                                </td>
                                </tr>
                                </tbody></table>           
                            </td>
                        </tr> 

                        <tr style="border-width: 1px">
                            <td><img src="./publications/MiniViT.png" style="margin-bottom: 0px"></td>
                            <td style="">
                                <table style="width: 100%;"><tbody><tr><td style="width: 100%; text-align: left;">
                                <p>
                                    <b>MiniViT: Compressing Vision Transformers with Weight Multiplexing</b><br>
                                   
                                    <div class="authors">
                                      
                                      <span class="author"><a href="https://scholar.google.com/citations?user=tbd4Tf4AAAAJ&hl=zh-CN&oi=ao">Jinnian Zhang</a></span>,
                                      <span class="author me">Houwen Peng*</span>,
                                      <span class="author"><a href="https://scholar.google.com/citations?user=sK4JUL4AAAAJ&hl=zh-CN&oi=sra">Kan Wu</a></span>,
                                      <span class="author"><a href="https://scholar.google.com/citations?user=cOPQtYgAAAAJ&hl=zh-CN&oi=ao">Mengchen Liu</a></span>,
                                      <span class="author"><a href="https://www.microsoft.com/en-us/research/people/bixi/">Bin Xiao</a></span>,
                                      <span class="author"><a href="https://jianlong-fu.github.io/">Jianlong Fu</a></span>,
                                      <span class="author"><a href="https://www.microsoft.com/en-us/research/people/luyuan/">Lu Yuan</a></span>
                                    </div>
                                    <div>
                                      <span class="venue"><a href="https://cvpr2022.thecvf.com/">CVPR 2022</a> </span> /
                                      <span class="tag"><a href="https://arxiv.org/pdf/2204.07154.pdf">Paper</a></span> / 
                                      <span class="tag"><a href="https://github.com/microsoft/Cream/tree/main/MiniViT">Code</a></span>
                                    <br>
                                      <br>
                                    </div>
                                </p>
                                </td><td style="width: 10px;">
                                </td>
                                </tr>
                                </tbody></table>           
                            </td>
                        </tr> 

                        <tr style="border-width: 1px">
                            <td><img src="./publications/arXiv20-CDARTS.PNG" style="margin-bottom: 0px"></td>
                            <td style="">
                                <table style="width: 100%;"><tbody><tr><td style="width: 100%; text-align: left;">
                                <p>
                                    <b>Cyclic Differentiable Architecture Search</b><br>
                                   
                                    <div class="authors">
                                      <span class="author"><a href="">Hongyuan Yu</a></span>,
                                      <span class="author me">Houwen Peng*</span>,
                                      <span class="author"><a href="">Yan Huang</a></span>,
                                      <span class="author"><a href="">Hao Du</a></span>,
                                      <span class="author"><a href="https://jianlong-fu.github.io/">Jianlong Fu</a></span>,
                                      <span class="author"><a href="http://cripac.ia.ac.cn/people/lwang/M-MCG/people.html">Liang Wang</a></span>,
                                      <span class="author"><a href="https://www3.cs.stonybrook.edu/~hling/">Haibin Ling</a></span>
                                    </div>
                                    <div>
                                      <span class="venue"><a href="https://arxiv.org/abs/2006.10724">TPAMI 2022</a> </span> /
                                      <span class="tag"><a href="https://arxiv.org/abs/2006.10724">Paper</a></span> / 
                                      <span class="tag"><a href="https://github.com/microsoft/Cream">Code</a></span>
                                    <br>
                                      <br>
                                    </div>
                                </p>
                                </td><td style="width: 10px;">
                                </td>
                                </tr>
                                </tbody></table>           
                            </td>
                        </tr> 


                        <tr style="border-width: 1px">
                            <td><img src="./publications/MS-2DTAN.PNG" style="margin-bottom: 0px"></td>
                            <td style="">
                                <table style="width: 100%;"><tbody><tr><td style="width: 100%; text-align: left;">
                                <p>
                                    <b>Multi-Scale 2D Temporal Adjacent Networks for Moment Localization with Natural Language</b><br>
                                   
                                    <div class="authors">
                                      <span class="author"><a href="https://sy-zhang.github.io/">Songyang Zhang</a></span>,
                                      <span class="author me">Houwen Peng*</span>,
                                      <span class="author"><a href="https://jianlong-fu.github.io/">Jianlong Fu</a></span>,
                                      <span class="author"><a href="https://scholar.google.com/citations?user=cpkrT44AAAAJ&hl=en&oi=ao">Yijuan Lu</a></span>,
                                      <span class="author"><a href="https://www.cs.rochester.edu/u/jluo/">Jiebo Luo</a></span>
                                    </div>
                                    <div>
                                      <span class="venue"><a href="https://arxiv.org/pdf/2012.02646.pdf">TPAMI 2021</a> </span> /
                                      <span class="tag"><a href="https://arxiv.org/pdf/2012.02646.pdf">Paper</a></span> / 
                                      <span class="tag"><a href="https://github.com/microsoft/2D-TAN">Code</a> </span>
                              
                                    </div>
                                    <div>
                                    <span class="highlight"><a href="http://hacs.csail.mit.edu/challenge2019.html">Rank #1</a></span> in <a href="http://hacs.csail.mit.edu/challenge2019.html"> HACS</a> Temporal Action Localization Challenge  
                                    </div>
                                </p>
                                </td><td style="width: 10px;">
                                </td>
                                </tr>
                                </tbody></table>           
                            </td>
                        </tr> 
                        
                        <tr style="border-width: 1px">
                            <td><img src="./publications/AutoFormerV2.PNG" style="margin-bottom: 0px"></td>
                            <td style="">
                                <table style="width: 100%;"><tbody><tr><td style="width: 100%; text-align: left;">
                                <p>
                                    <b>AutoFormerV2: Searching the Search Space of Vision Transformer</b><br>

                                    <div class="authors">
                                      <span class="author">Minghao Chen</span>,
                                      <span class="author">Kan Wu</span>,
                                      <span class="author">Bolin Ni</span>,
                                      <span class="author me">Houwen Peng*</span>,
                                      <span class="author">Bei Liu</span>,
                                      <span class="author"><a href="https://jianlong-fu.github.io/">Jianlong Fu</a></span>,
                                      <span class="author">Hongyang Chao</span>,
                                      <span class="author"><a href="https://www3.cs.stonybrook.edu/~hling/">Haibin Ling</a></span>
                                    </div>
                                    <div>
                                      <span class="venue"><a href="https://nips.cc/Conferences/2021">NeurIPS 2021</span> /
                                      <span class="tag"><a href="https://papers.nips.cc/paper/2021/hash/48e95c45c8217961bf6cd7696d80d238-Abstract.html">Paper</a></span> / 
                                      <span class="tag"><a href="https://github.com/microsoft/AutoML">Code</a> </span>
                                    <br>
                                      <br>
                                    </div>
                                </p>
                                </td><td style="width: 10px;">
                                </td>
                                </tr>
                                </tbody></table>           
                            </td>
                        </tr> 

                        <tr style="border-width: 1px">
                            <td><img src="./publications/VLP.PNG" style="margin-bottom: 0px"></td>
                            <td style="">
                                <table style="width: 100%;"><tbody><tr><td style="width: 100%; text-align: left;">
                                <p>
                                    <b>Probing Inter-modality: Visual Parsing with Self-Attention for Vision-and-Language Pre-training</b><br>

                                    <div class="authors">
                                      <span class="author">Hongwei Xue</span>,
                                      <span class="author">Yupan Huang</span>,
                                      <span class="author">Bei Liu</span>,
                                      <span class="author me">Houwen Peng</span>,
                                      <span class="author"><a href="https://jianlong-fu.github.io/">Jianlong Fu</a></span>,
                                      <span class="author">Houqiang Li</span>,
                                      <span class="author"><a href="https://www.cs.rochester.edu/u/jluo/">Jiebo Luo</a></span>
                                    </div>
                                    <div>
                                      <span class="venue"><a href="https://proceedings.neurips.cc/paper/2021/file/23fa71cc32babb7b91130824466d25a5-Paper.pdf">NeurIPS 2021</span> /
                                      <span class="tag"><a href="https://houwenpeng.com">Paper</a></span> 
                                    <br>
                                      <br>
                                    </div>
                                </p>
                                </td><td style="width: 10px;">
                                </td>
                                </tr>
                                </tbody></table>           
                            </td>
                        </tr> 

                        

                        <tr style="border-width: 1px">
                            <td><img src="./publications/USOT.PNG" style="margin-bottom: 0px"></td>
                            <td style="">
                                <table style="width: 100%;"><tbody><tr><td style="width: 100%; text-align: left;">
                                <p>
                                    <b>Learning to Track Objects from Unlabled Videos</b><br>

                                    <div class="authors">
                                      <span class="author">Jilai Zheng</span>,
                                      <span class="author"><a href="https://vision.sjtu.edu.cn/index.html">Chao Ma</a></span>,
                                      <span class="author me">Houwen Peng</span>,
                                      <span class="author"><a href="https://scholar.google.com/citations?user=nVgPQpoAAAAJ&hl=ja&oi=ao">Xiaokang Yang</a></span>
                                    </div>
                                    <div>
                                      <span class="venue"><a href="https://arxiv.org/abs/2108.12711">ICCV 2021</span> /
                                      <span class="tag"><a href="https://arxiv.org/abs/2108.12711">Paper</a></span> / 
                                      <span class="tag"><a href="https://github.com/VISION-SJTU/USOT">Code</a></span>
                                    <br>
                                      <br>
                                    </div>
                                </p>
                                </td><td style="width: 10px;">
                                </td>
                                </tr>
                                </tbody></table>           
                            </td>
                        </tr> 


                        <tr style="border-width: 1px">
                            <td><img src="./publications/iRPE.png" style="margin-bottom: 0px"></td>
                            <td style="">
                                <table style="width: 100%;"><tbody><tr><td style="width: 100%; text-align: left;">
                                <p>
                                    <b>Rethinking and Improving Relative Position Encoding for Vision Transformer</b><br>

                                    <div class="authors">
                                      <span class="author">Kan Wu</span>,
                                      <span class="author me">Houwen Peng*</span>,
                                      <span class="author">Minghao Chen</span>,
                                      <span class="author"><a href="https://jianlong-fu.github.io/">Jianlong Fu</a></span>,
                                      <span class="author"><a href="https://www3.cs.stonybrook.edu/~hling/">Hongyang Chao</a></span>
                                    </div>
                                    <div>
                                      <span class="venue"><a href="./publications/iRPE.pdf">ICCV 2021</span> /
                                      <span class="tag"><a href="./publications/iRPE.pdf">Paper</a></span> / 
                                      <span class="tag"><a href="https://github.com/microsoft/AutoML">Code</a></span>
                                    <br>
                                      <br>
                                    </div>
                                </p>
                                </td><td style="width: 10px;">
                                </td>
                                </tr>
                                </tbody></table>           
                            </td>
                        </tr> 


                        <tr style="border-width: 1px">
                            <td><img src="./publications/AutoFormerV2.gif" style="margin-bottom: 0px"></td>
                            <td style="">
                                <table style="width: 100%;"><tbody><tr><td style="width: 100%; text-align: left;">
                                <p>
                                    <b>AutoFormer: Searching Transformers for Visual Recognition</b><br>

                                    <div class="authors">
                                      <span class="author">Minghao Chen</span>,
                                       <span class="author me">Houwen Peng*</span>,
                                      <span class="author"><a href="https://jianlong-fu.github.io/">Jianlong Fu</a></span>,
                                      <span class="author"><a href="https://www3.cs.stonybrook.edu/~hling/">Haibin Ling</a></span>
                                    </div>
                                    <div>
                                      <span class="venue"><a href="https://arxiv.org/pdf/2107.00651.pdf">ICCV 2021</span> /
                                      <span class="tag"><a href="https://arxiv.org/pdf/2107.00651.pdf">Paper</a></span> / 
                                      <span class="tag"><a href="https://github.com/microsoft/AutoML">Code</a></span>
                                    <br>
                                      <br>
                                    </div>
                                </p>
                                </td><td style="width: 10px;">
                                </td>
                                </tr>
                                </tbody></table>           
                            </td>
                        </tr> 


                        
                        <tr style="border-width: 1px">
                            <td><img src="./publications/STARK.png" style="margin-bottom: 0px"></td>
                            <td style="">
                                <table style="width: 100%;"><tbody><tr><td style="width: 100%; text-align: left;">
                                <p>
                                    <b>Learning Spatio-Temporal Transformer for Visual Tracking</b><br>

                                    <div class="authors">
                                      <span class="author"><a href="https://scholar.google.com/citations?user=3f8qn4cAAAAJ&hl=ja&oi=ao">Bin Yan</a></span>,
                                      <span class="author me">Houwen Peng*</span>,
                                      <span class="author">Jianlong Fu</span>,
                                      <span class="author"><a href="https://scholar.google.com/citations?user=nVgPQpoAAAAJ&hl=ja&oi=ao">Dong Wang</a></span>,
                                      <span class="author"><a href="http://ice.dlut.edu.cn/lu/index.html">Huchuan Lu</a></span>  
                                    </div>
                                    <div>
                                      <span class="venue"><a href="https://arxiv.org/abs/2103.17154">ICCV 2021</span> /
                                      <span class="tag"><a href="https://arxiv.org/abs/2103.17154">Paper</a></span> / 
                                      <span class="tag"><a href="https://github.com/researchmm/Stark">Code</a></span>
                                    </div>
                                    <div>
                                    <span class="highlight"><a href="http://www.votchallenge.net/vot2021/program.html">Rank #1</a></span> in <a href="http://www.votchallenge.net/vot2021/program.html"> VOT-2021</a> Challenge RGB-D Track
                                    </div>
                                </p>
                                </td><td style="width: 10px;">
                                </td>
                                </tr>
                                </tbody></table>           
                            </td>
                        </tr> 


                        <tr style="border-width: 1px">
                            <td><img src="./publications/CVPR21-LightTrack.PNG" style="margin-bottom: 0px"></td>
                            <td style="">
                                <table style="width: 100%;"><tbody><tr><td style="width: 100%; text-align: left;">
                                <p>
                                    <b>LightTrack: Finding Lightweight Neural Networks for Object Tracking via One-Shot Architecture Search</b><br>
                                   
                                    <div class="authors">
                                      <span class="author"><a href="https://scholar.google.com/citations?user=3f8qn4cAAAAJ&hl=ja&oi=ao">Bin Yan<sup>&#8224;</sup></a></span>,
                                      <span class="author me">Houwen Peng<sup>&#8224;</sup></span>,
                                      <span class="author">Kan Wu<sup>&#8224;</sup></span>,
                                      <span class="author"><a href="https://scholar.google.com/citations?user=nVgPQpoAAAAJ&hl=ja&oi=ao">Dong Wang</a></span>,
                                      <span class="author"><a href="https://jianlong-fu.github.io/">Jianlong Fu</a></span>,
                                      <span class="author"><a href="http://ice.dlut.edu.cn/lu/index.html">Huchuan Lu</a></span>  
                                    </div>
                                    <div>
                                      <span class="venue"><a href="https://openaccess.thecvf.com/content/CVPR2021/papers/Yan_LightTrack_Finding_Lightweight_Neural_Networks_for_Object_Tracking_via_One-Shot_CVPR_2021_paper.pdf">CVPR 2021</a> </span> /
                                      <span class="tag"><a href="https://openaccess.thecvf.com/content/CVPR2021/papers/Yan_LightTrack_Finding_Lightweight_Neural_Networks_for_Object_Tracking_via_One-Shot_CVPR_2021_paper.pdf">Paper</a></span> / 
                                      <span class="tag"><a href="https://github.com/researchmm/LightTrack">Code</a></span>
                                    <br>
                                      <br>
                                    </div>
                                </p>
                                </td><td style="width: 10px;">
                                </td>
                                </tr>
                                </tbody></table>           
                            </td>
                        </tr> 

                        
                        <tr style="border-width: 1px">
                            <td><img src="./publications/CVPR21-NEAS.PNG" style="margin-bottom: 0px"></td>
                            <td style="">
                                <table style="width: 100%;"><tbody><tr><td style="width: 100%; text-align: left;">
                                <p>
                                    <b>One-Shot Neural Ensemble Architecture Search by Diversity-Guided Search Space Shrinking</b><br>
                                   
                                    <div class="authors">
                                      <span class="author">Minghao Chen</span>,
                                      <span class="author"><a href="https://jianlong-fu.github.io/">Jianlong Fu</a></span>,
                                      <span class="author"><a href="https://www3.cs.stonybrook.edu/~hling/">Haibin Ling</a></span>
                                    </div>                             
                                    <div>
                                      <span class="venue"><a href="http://cvpr2021.thecvf.com/">CVPR 2021</a> </span> /
                                      <span class="tag"><a href="https://arxiv.org/abs/2104.00597">Paper</a></span> / 
                                      <span class="tag"><a href="https://github.com/researchmm/NEAS">Code</a></span>
                                    <br>
                                      <br>
                                    </div>
                                </p>
                                </td><td style="width: 10px;">
                                </td>
                                </tr>
                                </tbody></table>           
                            </td>
                        </tr> 
                        

                        <tr style="border-width: 1px">
                            <td><img src="./publications/method_.png" style="margin-bottom: 0px"></td>
                            <td style="">
                                <table style="width: 100%;"><tbody><tr><td style="width: 100%; text-align: left;">
                                <p>
                                    <b>Cream of the Crop: Distilling Prioritized Paths For One-Shot Neural Architecture Search</b><br>
                                   
                                    <div class="authors">
                                      <span class="author me">Houwen Peng</span>,
                                      <span class="author">Hao Du</span>,
                                      <span class="author"><a href="https://scholar.google.com/citations?user=yfnvzxYAAAAJ&hl=ja&oi=ao">Hongyuan Yu</a></span>,
                                      <span class="author">Qi Li</span>,
                                      <span class="author"><a href="https://liaojing.github.io/html/">Jing Liao</a></span>,
                                      <span class="author"><a href="https://jianlong-fu.github.io/">Jianlong Fu</a></span>  
                                    </div>
                                    <div>
                                      <span class="venue"><a href="https://papers.nips.cc/paper/2020/file/d072677d210ac4c03ba046120f0802ec-Paper.pdf">NeurIPS 2020</a> </span> /
                                      <span class="tag"><a href="https://papers.nips.cc/paper/2020/file/d072677d210ac4c03ba046120f0802ec-Paper.pdf">Paper</a></span> / 
                                      <span class="tag"><a href="https://github.com/microsoft/Cream">Code</a></span>
                                    <br>
                                      <br>
                                    </div>
                                </p>
                                </td><td style="width: 10px;">
                                </td>
                                </tr>
                                </tbody></table>           
                            </td>
                        </tr> 


                        <tr style="border-width: 1px">
                            <td><img src="./publications/ECCV20-Ocean.PNG" style="margin-bottom: 0px"></td>
                            <td style="">
                                <table style="width: 100%;"><tbody><tr><td style="width: 100%; text-align: left;">
                                <p>
                                    <b>Ocean: Object-aware Anchor-free Tracking</b><br>
                                   
                                    <div class="authors">
                                      <span class="author"><a href="https://scholar.google.com/citations?user=7Ws0QHYAAAAJ&hl=EN">Zhipeng Zhang</a></span>,
                                      <span class="author me">Houwen Peng*</span>,
                                      <span class="author"><a href="https://jianlong-fu.github.io/">Jianlong Fu</a></span>,
                                      <span class="author"><a href="https://scholar.google.com/citations?user=tddnkNYAAAAJ&hl=EN/">Bing Li</a></span>,
                                      <span class="author"><a href="hhttp://people.ucas.ac.cn/~huweiming">Weiming Hu</a></span>
                                    </div>
                                    <div>
                                      <span class="venue"><a href="https://arxiv.org/abs/2006.10721">ECCV 2020</a> </span> /
                                      <span class="tag"><a href="https://arxiv.org/pdf/2006.10721.pdf">Paper</a></span> / 
                                      <span class="tag"><a href="https://github.com/researchmm/TracKit">Code</a></span>
                                    </div>
                                    <div>
                                    <span class="highlight"><a href="https://data.votchallenge.net/vot2020/presentations/vot2020-st.pdf">Rank #2</a></span> in <a href="https://data.votchallenge.net/vot2020/presentations/vot2020-st.pdf"> VOT-2020</a> Challenge Short-term and Real-Time Tracks
                                    </div>
                                </p>
                                </td><td style="width: 10px;">
                                </td>
                                </tr>
                                </tbody></table>           
                            </td>
                        </tr> 


                        <tr style="border-width: 1px">
                            <td><img src="./publications/CVPR20-TVOS.png" style="margin-bottom: 0px"></td>
                            <td style="">
                                <table style="width: 100%;"><tbody><tr><td style="width: 100%; text-align: left;">
                                <p>
                                    <b>A Transductive Approach for Semi-Supervised Video Object Segmentation</b><br>
                                   
                                    <div class="authors">
                                      <span class="author"><a href="https://www.linkedin.com/in/yizhuoz">Yizhuo Zhang<sup>&#8224;</sup></a></span>,
                                      <span class="author"><a href="https://www.microsoft.com/en-us/research/people/wuzhiron/">Zhirong Wu<sup>&#8224;</sup></a></span>,
                                      <span class="author me">Houwen Peng</span>,
                                      <span class="author"><a href="https://www.microsoft.com/en-us/research/people/stevelin/">Stephen Lin</a></span>
                                    </div>
                                    <div>
                                      <span class="venue"><a href="http://openaccess.thecvf.com/CVPR2020.py">CVPR 2020</a> </span> /
                                      <span class="tag"><a href="https://arxiv.org/pdf/2004.07193.pdf">Paper</a></span> / 
                                      <span class="tag"><a href="https://github.com/microsoft/transductive-vos.pytorch">Code</a></span>
                                    <br>
                                      <br>
                                    </div>
                                </p>
                                </td><td style="width: 10px;">
                                </td>
                                </tr>
                                </tbody></table>           
                            </td>
                        </tr> 

                         <tr style="border-width: 1px">
                            <td><img src="./publications/AAAI20-2D-TAN.PNG" style="margin-bottom: 0px"></td>
                            <td style="">
                                <table style="width: 100%;"><tbody><tr><td style="width: 100%; text-align: left;">
                                <p>
                                    <b>Learning 2D Temporal Localization Networks for Moment Localization with Natural Language</b><br>
                                   
                                    <div class="authors">
                                      <span class="author"><a href="https://sy-zhang.github.io/">Songyang Zhang</a></span>,
                                      <span class="author me">Houwen Peng*</span>,
                                      <span class="author"><a href="https://jianlong-fu.github.io/">Jianlong Fu</a></span>,
                                      <span class="author"><a href="https://www.cs.rochester.edu/u/jluo/">Jiebo Luo</a></span>
                                    </div>
                                    <div>
                                      <span class="venue"><a href="https://aaai.org/Conferences/AAAI-20/">AAAI 2020</a> </span> /
                                      <span class="tag"><a href="https://arxiv.org/pdf/1912.03590.pdf">Paper</a></span> / 
                                      <span class="tag"><a href="https://github.com/microsoft/2D-TAN">Code</a> </span>
                              
                                    </div>
                                    <div>
                                    <span class="highlight"><a href="http://hacs.csail.mit.edu/challenge2019.html">Rank #1</a></span> in <a href="http://hacs.csail.mit.edu/challenge2019.html"> HACS</a> Temporal Action Localization Challenge  
                                    </div>
                                </p>
                                </td><td style="width: 10px;">
                                </td>
                                </tr>
                                </tbody></table>           
                            </td>
                        </tr> 


                        <tr style="border-width: 1px">

                            <td><img src="./publications/CVPR19-SiamDW.gif" style="margin-bottom: 0px"></td>
                            <td style="">
                                <table style="width: 100%;"><tbody><tr><td style="width: 100%; text-align: left;">
                                <p>
                                    <b>Deeper and Wider Siamese Networks for Real-time Visual Tracking</b><br>
                                   
                                    <div class="authors">
                                      <span class="author"><a href="https://scholar.google.com/citations?user=7Ws0QHYAAAAJ&hl=EN">Zhipeng Zhang</a></span>,
                                      <span class="author me">Houwen Peng*</span>
                                    </div>
                                    <div>
                                      <span class="venue"><a href="http://openaccess.thecvf.com/content_CVPR_2019/html/Zhang_Deeper_and_Wider_Siamese_Networks_for_Real-Time_Visual_Tracking_CVPR_2019_paper.html">CVPR 2019</a> <span class="highlight"><a href="https://www.youtube.com/watch?v=j7A83F6PRAE">Oral Presentation</a></span> </span> /
                                      <span class="tag"><a href="http://openaccess.thecvf.com/content_CVPR_2019/html/Zhang_Deeper_and_Wider_Siamese_Networks_for_Real-Time_Visual_Tracking_CVPR_2019_paper.html">Paper</a></span> / 
                                      <span class="tag"><a href="https://github.com/researchmm/SiamDW">Code</a> </span>
                                    </div>
                                     <div>
                                    <span class="highlight"><a href="http://www.votchallenge.net/vot2019/program.html">Rank #1</a></span> in <a href="http://www.votchallenge.net/vot2019/program.html"> VOT-2019</a> Challenge RGB-D Track
                                    </div>
                                </p>
                                </td><td style="width: 0px;">
                                </td>
                                </tr>
                                </tbody></table>           
                            </td>
                        </tr> 


                         <tr style="border-width: 1px">

                            <td><img src="./publications/MM19.PNG" style="margin-bottom: 0px"></td>
                            <td style="">
                                <table style="width: 100%;"><tbody><tr><td style="width: 100%; text-align: left;">
                                <p>
                                    <b>AI Coach: Deep Human Pose Estimation and Analysis for Personalized Athletic Training Assistance</b><br>
                                   
                                    <div class="authors">
                                      <span class="author"><a href="">Jianbo Wang</a></span>,
                                      <span class="author"><a href="https://scholar.google.com/citations?user=PFiDkUoAAAAJ&hl=en">Kai Qiu</a></span>,
                                      <span class="author me">Houwen Peng</span>
                                      <span class="author"><a href="https://jianlong-fu.github.io/">Jianlong Fu</a></span>,
                                      <span class="author"><a href="https://scholar.google.com/citations?user=SC-WmzwAAAAJ&hl=EN">Jianke Zhu</a></span>,
                                    </div>
                                    <div>
                                      <span class="venue"><a href="https://dl.acm.org/doi/abs/10.1145/3343031.3350609">ACM Multimedia 2019</a> </span> /
                                      <span class="tag"><a href="https://dl.acm.org/doi/abs/10.1145/3343031.3350609">Paper</a></span>
                                    <br>
                                      <br>
                                    </div>
                                </p>
                                </td><td style="width: 0px;">
                                </td>
                                </tr>
                                </tbody></table>           
                            </td>
                        </tr> 


                        <tr style="border-width: 1px">
                            <td><img src="./publications/PAMI17-LiBing.PNG" style="margin-bottom: 0px"></td>
                            <td style="">
                                <table style="width: 100%;"><tbody><tr><td style="width: 100%; text-align: left;">
                                <p>
                                    <b>Multi-view Multi-instance Learning based on Joint Sparse Representation and Multi-view Dictionary Learning</b><br>
                                   
                                    <div class="authors">
                                      <span class="author"><a href="https://scholar.google.com/citations?user=tddnkNYAAAAJ&hl=EN/">Bing Li</a></span>,
                                      <span class="author"><a href="https://scholar.google.com/citations?user=JsxBjD0AAAAJ&hl=en/">Weihua Xiong</a></span>,
                                      <span class="author me">Houwen Peng</span>,
                                      <span class="author"><a href="hhttp://people.ucas.ac.cn/~huweiming">Weiming Hu</a></span>,
                                      <span class="author"><a href="http://www.dcs.bbk.ac.uk/~sjmaybank/">Stephen J. Maybank</a></span>
                                    </div>
                                    <div>
                                      <span class="venue"><a href="https://ieeexplore.ieee.org/abstract/document/7855789">TPAMI 2017</a> </span> /
                                      <span class="tag"><a href="http://www.dcs.bbk.ac.uk/~sjmaybank/MultiView.pdf">Paper</a></span> 
                                    <br>
                                      <br>
                                    </div>
                                </p>
                                </td><td style="width: 0px;">
                                </td>
                                </tr>
                                </tbody></table>           
                            </td>
                        </tr> 


                        <tr style="border-width: 1px">
                            <td><img src="./publications/CVPR13.PNG" style="margin-bottom: 0px"></td>
                            <td style="">
                                <table style="width: 100%;"><tbody><tr><td style="width: 100%; text-align: left;">
                                <p>
                                    <b>Illumination Estimation based on Bilayer Sparse Coding</b><br>
                                   
                                    <div class="authors">
                                      <span class="author"><a href="https://scholar.google.com/citations?user=tddnkNYAAAAJ&hl=EN/">Bing Li</a></span>,
                                      <span class="author"><a href="https://scholar.google.com/citations?user=JsxBjD0AAAAJ&hl=en/">Weihua Xiong</a></span>,
                                      <span class="author"><a href="hhttp://people.ucas.ac.cn/~huweiming">Weiming Hu</a></span>,
                                      <span class="author me">Houwen Peng</span>
                                    </div>
                                    <div>
                                      <span class="venue"><a href="https://www.cv-foundation.org/openaccess/content_cvpr_2013/papers/Li_Illumination_Estimation_Based_2013_CVPR_paper.pdf">CVPR 2013</a> </span> /
                                      <span class="tag"><a href="https://www.cv-foundation.org/openaccess/content_cvpr_2013/papers/Li_Illumination_Estimation_Based_2013_CVPR_paper.pdf">Paper</a></span> 
                                    <br>
                                      <br>
                                    </div>
                                </p>
                                </td><td style="width: 0px;">
                                </td>
                                </tr>
                                </tbody></table>           
                            </td>
                        </tr> 
                        
                        <tr style="border-width: 1px">
                            <td><img src="./publications/PAMI17-SMD.jpg" style="margin-bottom: 0px"></td>
                            <td style="">
                                <table style="width: 100%;"><tbody><tr><td style="width: 100%; text-align: left;">
                                <p>
                                    <b>Salient Object Detection via Structured Matrix Decomposition</b><br>
                                   
                                    <div class="authors">
                                      <span class="author me">Houwen Peng</span>,
                                      <span class="author"><a href="https://www3.cs.stonybrook.edu/~hling/">Haibin Ling</a></span>,
                                      <span class="author"><a href="https://scholar.google.com/citations?user=tddnkNYAAAAJ&hl=EN/">Bing Li</a></span>,
                                      <span class="author"><a href="https://scholar.google.com/citations?user=JsxBjD0AAAAJ&hl=en/">Weihua Xiong</a></span>,
                                      <span class="author"><a href="hhttp://people.ucas.ac.cn/~huweiming">Weiming Hu</a></span>,
                                      <span class="author"><a href="http://www.dcs.bbk.ac.uk/~sjmaybank/">Stephen J. Maybank</a></span>
                                    </div>
                                    <div>
                                      <span class="venue"><a href="https://ieeexplore.ieee.org/abstract/document/7464858">TPAMI 2017</a> <span class="highlight"><a href="https://ieeexplore.ieee.org/abstract/document/7464858">Featured Paper</a></span> </span> /
                                      <span class="tag"><a href="https://eprints.bbk.ac.uk/14986/1/14986.pdf">Paper</a></span> / 
                                      <span class="tag"><a href="https://sites.google.com/site/salientobjectdetection/need-to-knows">Code</a> </span> /
                                      <span class="tag"><a href="https://sites.google.com/site/salientobjectdetection/home">Project Webpage (Updated)</a></span> 
                                    <br>
                                      <br>
                                    </div>
                                </p>
                                </td><td style="width: 0px;">
                                </td>
                                </tr>
                                </tbody></table>           
                            </td>
                        </tr> 



                        <tr style="border-width: 1px">
                            <td><img src="./publications/MM15.PNG" style="margin-bottom: 0px"></td>
                            <td style="">
                                <table style="width: 100%;"><tbody><tr><td style="width: 100%; text-align: left;">
                                <p>
                                    <b>Predicting Image Memorability by Multi-view Adaptive Regression</b><br>
                                   
                                    <div class="authors">
                                      <span class="author me">Houwen Peng</span>,
                                      <span class="author"><a href="">Kai Li</a></span>,
                                      <span class="author"><a href="https://scholar.google.com/citations?user=tddnkNYAAAAJ&hl=EN/">Bing Li</a></span>,
                                      <span class="author"><a href="https://www3.cs.stonybrook.edu/~hling/">Haibin Ling</a></span>,
                                      <span class="author"><a href="https://scholar.google.com/citations?user=JsxBjD0AAAAJ&hl=en/">Weihua Xiong</a></span>,
                                      <span class="author"><a href="hhttp://people.ucas.ac.cn/~huweiming">Weiming Hu</a></span>
                                    </div>
                                    <div>
                                      <span class="venue"><a href="https://dl.acm.org/doi/10.1145/2733373.2806303">ACM Multimedia 2015</a> </span> /
                                      <span class="tag"><a href="./publications/MM15.pdf">Paper</a></span> 
                                    <br>
                                      <br>
                                    </div>
                                </p>
                                </td><td style="width: 0px;">
                                </td>
                                </tr>
                                </tbody></table>           
                            </td>
                        </tr> 


                        <tr style="border-width: 1px">
                            <td><img src="./publications/ECCV14-RGBD.png" style="margin-bottom: 0px"></td>
                            <td style="">
                                <table style="width: 100%;"><tbody><tr><td style="width: 100%; text-align: left;">
                                <p>
                                    <b>RGBD Salient Object Detection: A Benchmark and Algorithms</b><br>
                                   
                                    <div class="authors">
                                      <span class="author me">Houwen Peng</span>,
                                      <span class="author"><a href="https://scholar.google.com/citations?user=tddnkNYAAAAJ&hl=EN/">Bing Li</a></span>,
                                      <span class="author"><a href="https://scholar.google.com/citations?user=JsxBjD0AAAAJ&hl=en/">Weihua Xiong</a></span>,
                                      <span class="author"><a href="hhttp://people.ucas.ac.cn/~huweiming">Weiming Hu</a></span>,
                                      <span class="author"><a href="https://people.eecs.berkeley.edu/~janner/">Rongrong Ji</a></span>
                                    </div>
                                    <div>
                                      <span class="venue"><a href="https://ieeexplore.ieee.org/abstract/document/7464858">ECCV 2014 </span> /
                                      <span class="tag"><a href="https://link.springer.com/content/pdf/10.1007%2F978-3-319-10578-9_7.pdf">Paper</a></span> / 
                                      <span class="tag"><a href="https://sites.google.com/site/rgbdsaliency/code">Code</a> </span> /
                                      <span class="tag"><a href="https://sites.google.com/site/rgbdsaliency/home">Project Webpage</a></span> 
                                    <br>
                                      <br>
                                    </div>
                                </p>
                                </td><td style="width: 0px;">
                                </td>
                                </tr>
                                </tbody></table>           
                            </td>
                        </tr> 




                        <tr style="border-width: 1px">
                            <td><img src="./publications/AAAI13-LSMD.PNG" style="margin-bottom: 0px"></td>
                            <td style="">
                                <table style="width: 100%;"><tbody><tr><td style="width: 100%; text-align: left;">
                                <p>
                                    <b>Salient Object Detection via Low-rank and Structured Sparse Matrix Decomposition</b><br>
                                   
                                    <div class="authors">
                                      <span class="author me">Houwen Peng</span>,
                                      <span class="author"><a href="https://scholar.google.com/citations?user=tddnkNYAAAAJ&hl=EN/">Bing Li</a></span>,
                                      <span class="author"><a href="https://people.eecs.berkeley.edu/~janner/">Rongrong Ji</a></span>,
                                      <span class="author"><a href="https://people.eecs.berkeley.edu/~janner/">Weiming Hu</a></span>,
                                      <span class="author"><a href="https://scholar.google.com/citations?user=JsxBjD0AAAAJ&hl=en/">Weihua Xiong</a></span>
                                    </div>
                                    <div>
                                      <span class="venue"><a href="https://ieeexplore.ieee.org/abstract/document/7464858">AAAI 2013</a> <span class="highlight"><a href="https://docs.google.com/uc?authuser=0&id=0B1wzzt1_uP1rdldWNnVaU3BwQUk&export=download">Oral Presentation</a></span> </span> /
                                      <span class="tag"><a href="https://www.aaai.org/ocs/index.php/AAAI/AAAI13/paper/view/6290/7270">Paper</a></span> / 
                                      <span class="tag"><a href="https://sites.google.com/site/salientobjectdetection/need-to-knows">Code</a> </span> /
                                      <span class="tag"><a href="https://sites.google.com/site/salientobjectdetection/home">Project Webpage (Updated)</a></span> 
                                    <br>
                                      <br>
                                    </div>
                                </p>
                                </td><td style="width: 0px;">
                                </td>
                                </tr>
                                </tbody></table>           
                            </td>
                        </tr> 


                    </tbody></table>

             <br><br><h1>Awards and Honors</h1>
             <hr3/>
                <ul style="list-style-type:disc; margin-left: 20px">
                    <li> <span class="highlight"> 1st Place Winner </span> of <a href="https://www.votchallenge.net/vot2021/program.html"> Visual Object Tracking (VOT) Challenge 2021 - RGBD Track </a></li> 
                    <li> <span class="highlight"> 1st Place Winner </span> of <a href="http://hacs.csail.mit.edu/challenge2019.html"> HACS Temporal Action Localization Challenge 2019</a>  </li> 
                    <li> <span class="highlight"> 1st Place Winner </span> of <a href="https://www.votchallenge.net/vot2019/program.html"> Visual Object Tracking (VOT) Challenge 2019 - RGBD Track </a></li> 
                    <li>2rd and 3th Place Winners of <a href="https://www.votchallenge.net/vot2019/program.html"> Visual Object Tracking (VOT) Challenge 2019 - Long-term and RGBT Tracks </a></li> 
                    <li>Qualcomm Innovation Award</li>
                    <li>Rokid AI Fellowship</li>
                    <li>National Scholarship</li>
                </ul>
            
             <br><br><h1>Activities</h1>
             <hr3/>

                <ul style="list-style-type:disc; margin-left: 20px">

                    <!--
                    <li>
                    <font face="Arial" size="3.5" color="black"> 
                    04/2020 - If you are looking for internship opportunities, please drop me an <a href="mailto:houwen.peng@microsoft.com">email</a>.
                    </font>
                    </li>
                    -->
                    <font face="Arial" size="3.5" color="black"> 
                    <font face="Arial" size="3.5" color="black">
                    Area Chair / Senior PC for
                    </font>
                    <li>
                    <font face="Arial" size="3.5" color="black"> 
                    ACM International Conference on Multimedia (MM), 2021, 2022, 2023
                    </li>
                    <li>
                    AAAI Conference on Artificial Intelligence (AAAI), 2022.
                    </font>
                    </li> 
                    Reviewer / Program Committee for
                    </font>
                    <li>
                    <font face="Arial" size="3.5" color="black"> 
                    International Conference on Learning Representations (ICLR), 2021, 2022
                    </font>
                    </li>
                    <li>
                    <font face="Arial" size="3.5" color="black"> 
                    International Conference on Machine Learning (ICML), 2021, 2022
                    </font>
                    </li>
                    <li>
                    <font face="Arial" size="3.5" color="black"> 
                    AAAI Conference on Artificial Intelligence (AAAI), 2019, 2020, 2021, 2022
                    </font>
                    </li>
                    <li>
                    <font face="Arial" size="3.5" color="black"> 
                    Advances in Neural Information Processing Systems (NIPS), 2020, 2021, 2022, 2023
                    </font>
                    </li>
                    <li>
                    <font face="Arial" size="3.5" color="black"> 
                    IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2016, 2019, 2020, 2021, 2022, 2023
                    </font>
                    </li>
                    <li>
                    <font face="Arial" size="3.5" color="black"> 
                    IEEE International Conference on Computer Vision (ICCV), 2017, 2019, 2021, 2023
                    </font>
                    </li
>                    <li>
                    <font face="Arial" size="3.5" color="black"> 
                    European Conference on Computer Vision (ECCV), 2018, 2020, 2022
                    </font>
                    </li>
                    <li>
                    <font face="Arial" size="3.5" color="black"> 
                    Winter Conference on Applications of Computer Vision, 2021, 2022
                    </font>
                    </li>
                    <li>
                    <font face="Arial" size="3.5" color="black"> 
                    IEEE International Conference on Robotics and Automation (ICRA), 2013, 2015, 2020
                    </font>
                    </li>
                    <li>
                    <font face="Arial" size="3.5" color="black"> 
                    IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI
)                    </font>
                    </li>
                    <li>
                    <font face="Arial" size="3.5" color="black"> 
                    IEEE Transactions on Image Processing (TIP)
                    </font>
                    </li>
                    <li>
                    <font face="Arial" size="3.5" color="black"> 
                    IEEE Transactions on Multimedia (TMM)
                    </font>
                    </li>
                    <li>
                    <font face="Arial" size="3.5" color="black"> 
                    IEEE Transactions on Circuits and Systems for Video Technology (TCSVT)
                    </font>
                    </li>
                    <li>
                    <font face="Arial" size="3.5" color="black"> 
                    Pattern Recognition (PR) 
                    </font>
                    </li>
                    </ul>

             <br>
              
             <!--<footer >
               <br>
                <div align='center'> &nbsp&nbsp &copy; 2020 HOUWEN PENG</div>
                <div align='center'> &nbsp; <a href="https://www.hit-counts.com/"><img alt="HTML Counter" border="0" src="http://www.hit-counts.com/counter.php?t=MTQ0NjY3Nw=="></a> </div>
            </footer>  
             --> 
            </div>
            </div>
        </div>
        <!-- ENDS MAIN -->  
          

    
</div>
</div>
</body>
</html>

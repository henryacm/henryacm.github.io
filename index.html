<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">

<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
    <head>
        <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
        <title>Houwen Peng - Microsoft Research Asia</title>
        <meta name="keywords" content="Houwen Peng - Microsoft Research Asia, Houwen Peng Homepage, Houwen Peng, Peng Houwen, Microsoft, Microsft Research, MSRA, Microsoft Research Asia,">
            
        <!-- CSS -->
        <link href="css" rel="stylesheet" type="text/css">
        <link rel="stylesheet" href="style.css" type="text/css" media="screen">
        <!-- ENDS CSS -->
        <script src="http://ajax.googleapis.com/ajax/libs/jquery/1.10.2/jquery.min.js"></script>
        <link rel="shortcut icon" href="./icon/ms.ico">
        <!-- ENDS JS -->  
    </head> 
    <body>
        <!-- MAIN -->
        <div id="">
           <div id="match-nav-wrapper">
               <div id="match-nav-bar">
                     <table>
                        <thead>
                            <tr valign="bottom">
                                <th width="" style="font-size: 25px;  color: #00A4EF"></th>
                                <th width=55% ></th>
                                <th width=""><a href="index.html">Homepage</a> </th>
                                <th width=""><a href="publication.html">Research</a></th>
                                <th width=""><a href="group.html">Subgroup</a></th>
                            </tr>
                        </thead>
                    </table>
                </div>
            </div>
        <!-- HEADER -->


                        
             <div id="main-wrapper">
                    <div id="portfolio">
                        <div id="portfolio-photo"><img src="./group/houwen-home1.jpg" class="img-thumbnail" >
                            <!--
                            <br>
                            <ul class="social">
                                <li class="github"><a href="https://github.com/penghouwen">GitHub</a></li>
                                <li class="googlescholar"><a href="https://scholar.google.com/citations?user=UYlhQS8AAAAJ&hl=EN">Google Scholar</a></li>
                                <li class="linkedin"><a href="https://www.linkedin.com/in/houwen-peng-73424737/">LinkedIn</a></li>
                                <li style="clear:both:" class="resume"><a href="">Resume</a></li>
                            </ul>
                            </br>
                            <br>
                            -->
                        </div>
                        <div id="portfolio-bio">
                            <br>
                            <font face="Arial" size="5">  Houwen Peng</font> &nbsp&nbsp&nbsp <font face="KaiTi" size="4"> <span lang="zh-cn">(å½­åŽšæ–‡)</span> </font> <br>
                            <font face="Arial" size="3.5"> 
                            <br>
                            I am a senior researcher working on computer vision and deep learning at <a href="https://www.microsoft.com/en-us/research/lab/microsoft-research-asia/"> Microsoft Research Asia. </a>
                            My current research interest includes tiny and efficient deep learning, video object tracking, segmentation and detection, vision transformer, neural architecture search, model compression, vision-language intelligence, saliency detection, etc.
                            <br> 

                            <br>    
                            Email:  houwen.peng@microsoft.com  
                            <br>
                            Address: 13423 Building 2, Microsoft, No. 5 Danling St., Haidian, Beijing 100080

                            <br>
                            <br>
                            <B><font face="Arial" size="3"> If you are looking for internship opportunities, please drop me an <a href="mailto:houwen.peng@microsoft.com">email</a></font></B>.
                            <br>
                            <br>

                            </font>
                            </font>

                        </div>
                    </div>
             </div>

             <p><span>&nbsp</span></p>
             <p><span>&nbsp</span></p> 
             <p><span>&nbsp</span></p>
             <p><span>&nbsp</span></p> 
             <p><span>&nbsp</span></p>
             <p><span>&nbsp</span></p>

             <div id="main-wrapper2">
                <div id="portfolio">   
                <div>
                    
                    <br>

                    <div>
                    <B><font face="Arial" size="3.5">Biography</font></B>: <font face="Arial" size="3.5"> Houwen is a senior researcher working on computer vision and deep learning at <a href="https://www.microsoft.com/en-us/research/people/hopeng/">Microsoft Research</a> as of 2018. Before that he was a senior engineer at <a href="https://www.qualcomm.com/invention/artificial-intelligence/ai-research/">Qualcomm AI Research</a>. He received Ph.D. from <a href="http://www.nlpr.ia.ac.cn/cn/index.html">NLPR</a>, Instituation of Automation, Chinese Academy of Sciences in 2016. From 2015 to 2016, he worked as a visiting research scholar at <a href="https://www3.cs.stonybrook.edu/~hling/group.htm">Temple University</a>. His research interest includes tiny and efficient deep learning, video recognition, tracking, segmentation and detection, vision transformer, neural architecture search, model compression, vision-language intelligence, saliency detection, etc.
                    </font> 
                    </div>
                </div>

                <div >
                    <ul style="list-style-type:disc; margin-left: 2px">
                    <!--<br><strong><font face="Arial" size="4">  News </font> </strong> </br> -->
                    <br>
                    <br>
                    <div style="display:inline-block;"><font face="Arial" size="5"> &nbsp&nbsp <B>News</B> </font></div>
                    <hr/>

                    
                    </ul>

                    <ul style="list-style-type:disc; margin-left: 20px">

                    <!--
                    <li>
                    <B> <font face="Arial" size="3.5" color="black"> 
                    09/2021 - We're hiring research interns, pls feel free to drop me an <a href="mailto:houwen.peng@microsoft.com">email</a> if you are interested. </B>
                    </font>
                    </li>
                   
                    <li>
                    <B> <font face="Arial" size="3.5" color="black"> 
                    10/2022 - We're hiring research interns, pls feel free to drop me an <a href="mailto:houwen.peng@microsoft.com">email</a>. </B>
                    </font>
                    </li>
                     -->

                    
                    <li>
                    <font face="Arial" size="3.5" color="black"> 
                    <font face="Arial" size="3.5">11/2023</font> - <a href="https://github.com/Xwin-LM/Xwin-LM">Xwin-LM</a> v0.1 ranked as the top-1 open-sourced model on <a href="https://tatsu-lab.github.io/alpaca_eval/">AlpacaEval benchmark</a>. v0.3 is coming, stay tuned.
                    </font>
                    </li>


                    <li>
                    <font face="Arial" size="3.5" color="black"> 
                    <font face="Arial" size="3.5">10/2023</font> - <a href="https://arxiv.org/abs/2310.18313">FP8-LM</a> released.
                    </font>
                    </li>

                    <li>
                    <font face="Arial" size="3.5" color="black"> 
                    <font face="Arial" size="3.5">09/2023</font> - <a href="https://github.com/microsoft/Cream/tree/main/TinyCLIP">TinyCLIP</a> code released.
                    </font>
                    </li>

                    <li>
                    <font face="Arial" size="3.5" color="black"> 
                    <font face="Arial" size="3.5">09/2023</font> - <a href="https://arxiv.org/abs/2308.00906">ImageBrush</a> accepted by NeurIPS'2023. 
                    </font>
                    </li>

                    <li>
                    <font face="Arial" size="3.5" color="black"> 
                    <font face="Arial" size="3.5">07/2023</font> - Three papers accepted by ICCV2023, including TinyCLIP, A-CLIP, and Efficient Tracker.
                    </font>
                    </li>

                    <li>
                    <font face="Arial" size="3.5" color="black"> 
                    <font face="Arial" size="3.5">05/2023</font> - <a href="https://github.com/microsoft/Cream/tree/main/EfficientViT">EfficientViT</a> code released.
                    </font>
                    </li>

                    <li>
                    <font face="Arial" size="3.5" color="black"> 
                    <font face="Arial" size="3.5">05/2023</font> - <a href="https://github.com/microsoft/VideoX/tree/master/SeqTrack">SeqTrack</a> code released.
                    </font>
                    </li>

                    <li>
                    <font face="Arial" size="3.5" color="black"> 
                    <font face="Arial" size="3.5">03/2023</font> - Three papers accepted by CVPR2023, including EfficientViT, SeqTrack, and iCLIP.
                    </font>
                    </li>


                    <li>
                    <font face="Arial" size="3.5" color="black"> 
                    <font face="Arial" size="3.5">10/2022</font> - Papers with code <a href="https://paperswithcode.com/newsletter/36">Newsletter #36</a> picked up <a href="https://github.com/microsoft/VideoX/tree/master/X-CLIP">X-CLIP</a>. 
                    </font>
                    </li>


                    <li>
                    <font face="Arial" size="3.5" color="black"> 
                    <font face="Arial" size="3.5">09/2022</font> - <a href="https://github.com/microsoft/Cream/tree/main/TinyViT">PointNeXt</a> accepted by NeurIPS'2022. 
                    </font>
                    </li>

                    <li>
                    <font face="Arial" size="3.5" color="black"> 
                    <font face="Arial" size="3.5">09/2022</font> - <a href="https://arxiv.org/pdf/2208.02816.pdf">X-CLIP</a> has been integrated into <a href="https://huggingface.co/docs/transformers/model_doc/xclip">ðŸ¤— Hugging Face</a>. 
                    </font>
                    </li>

                    <li>
                    <font face="Arial" size="3.5" color="black"> 
                    <font face="Arial" size="3.5">09/2022</font> - Papers with code <a href="https://paperswithcode.com/newsletter/33">Newsletter #33</a> picked up <a href="https://arxiv.org/pdf/2206.04670.pdf">PointNeXt</a>. 
                    </font>
                    </li>

                    <li>
                    <font face="Arial" size="3.5" color="black"> 
                    <font face="Arial" size="3.5">09/2022</font> - <a href="https://github.com/microsoft/Cream/tree/main/AutoFormer">AutoFormerV2</a> was integrated into <a href="https://github.com/rwightman/pytorch-image-models">Timm</a>, while <a href="https://github.com/researchmm/Stark"> STARK</a> was integrated into <a href="https://github.com/open-mmlab/mmtracking">OpenMMTracking</a>. 
                    </font>
                    </li>

                    <li>
                    <font face="Arial" size="3.5" color="black"> 
                    <font face="Arial" size="3.5">08/2022</font> - <a href="https://github.com/microsoft/Cream/tree/main/TinyViT">TinyViT</a> is selected as one of the popular Github projects in July. <a href="https://www.reddit.com/r/MachineLearning/comments/wi05tg/d_most_popular_ai_research_july_2022_pt_2_ranked/">Reddit</a> and <a href="https://mp.weixin.qq.com/s/qGRUkt5glw2CiANCT2_3mw">XinZhiYuan</a>. 
                    </font>
                    </li>

                    <li>
                    <font face="Arial" size="3.5" color="black"> 
                    <font face="Arial" size="3.5">08/2022</font> - <a href="https://github.com/microsoft/VideoX/tree/master/X-CLIP">X-CLIP</a> released. 
                    </font>
                    </li>

                    <li>
                    <font face="Arial" size="3.5" color="black"> 
                    <font face="Arial" size="3.5">08/2022</font> - <a href="https://github.com/microsoft/Cream/tree/main/TinyViT">TinyViT</a> released. 
                    </font>
                    </li>

                    <li>
                    <font face="Arial" size="3.5" color="black"> 
                    <font face="Arial" size="3.5">07/2022</font> - A <a href="https://mp.weixin.qq.com/s/reppBhb__4jeQTsPH5eg5g">post</a> on our recent tiny and efficient models. 
                    </font>
                    </li>


                    <li>
                    <font face="Arial" size="3.5" color="black"> 
                    <font face="Arial" size="3.5">07/2022</font> - Two papers accepted by ECCV2022, in which <a href="https://arxiv.org/pdf/2208.02816.pdf">X-CLIP</a> was finally selected as an ORAL. 
                    </font>
                    </li>

                    <li>
                    <font face="Arial" size="3.5" color="black"> 
                    <font face="Arial" size="3.5">06/2022</font> - An interesting work on 3D point representation learning <a href="https://arxiv.org/pdf/2206.04670.pdf">PointNeXt</a>.
                    </font>
                    </li> 

                    <li>
                    <font face="Arial" size="3.5" color="black"> 
                    <font face="Arial" size="3.5">04/2022</font> - Our work <a href="https://arxiv.org/pdf/2204.07154.pdf">MiniViT</a> was accepted to <a href="https://cvpr2022.thecvf.com/">CVPR 2022</a>.  <a href="https://github.com/microsoft/Cream/tree/main/MiniViT">Code</a> is available. 
                    </font>
                    </li>

                    <li>
                    <font face="Arial" size="3.5" color="black"> 
                    <font face="Arial" size="3.5">02/2022</font> - Our <a href="https://arxiv.org/abs/2006.10724">CDARTS</a> is finally accepted by <a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=34">TPAMI</a>. CDARTS <a href="https://github.com/microsoft/Cream/tree/main/CDARTS">Detection</a> and <a href="https://github.com/microsoft/Cream/tree/main/CDARTS">Segmentation</a> code is available now. 
                    </font>
                    </li>

                    <li>
                    <font face="Arial" size="3.5" color="black"> 
                    <font face="Arial" size="3.5">01/2022</font> - Invited as an Area Chair of <a href="https://2022.acmmm.org/">ACM Multimedia 2022</a>.
                    </font>
                    </li>

                    <li>
                    <font face="Arial" size="3.5" color="black"> 
                    12/2021 - Our visual grounding work <a href="https://ieeexplore.ieee.org/abstract/document/9580623">MS-2D-TAN</a> was reported by <a href="https://mp.weixin.qq.com/s/ptg-CKoCm0WMpPCpMVAGvA">1</a>, <a href="
                    https://www.sohu.com/a/512044757_129720">2</a>, <a href="
                    https://cloud.tencent.com/developer/article/1926574">3</a>, <a href="https://mp.weixin.qq.com/s/v_pJHtkFFejwB7OBUMlOrA">4</a> ....
                    </font>
                    </li>


                    <li>
                    <font face="Arial" size="3.5" color="black"> 
                    11/2021 - Our <a href="https://openaccess.thecvf.com/content/ICCV2021/papers/Yan_Learning_Spatio-Temporal_Transformer_for_Visual_Tracking_ICCV_2021_paper.pdf">STARK</a> tracker achieved the <a href="http://www.votchallenge.net/vot2021/program.html"> Winner</a> in VOT2021 challenge. <a href="https://github.com/researchmm/Stark"> Code</a> released.
                    </font>
                    </li>

                    <li>
                    <font face="Arial" size="3.5" color="black"> 
                    <font face="Arial" size="3.5">10/2021</font> - Our video grounding work, <a href="https://github.com/microsoft/2D-TAN"> MS-2D-TAN</a>, accepted by TPAMI. Congrats to Songyang!
                    </font>
                    </li>

                    <li>
                    <font face="Arial" size="3.5" color="black"> 
                    <font face="Arial" size="3.5">09/2021</font> - <a href="https://github.com/microsoft/Cream/tree/main/AutoFormer">AutoFormerV2</a> accepted by NeurIPS'21. Two papers got in, congrats!
                    </font>
                    </li>

                    <li>
                    <font face="Arial" size="3.5" color="black"> 
                    <font face="Arial" size="3.5">08/2021</font> - AutoFormer <a href="https://github.com/microsoft/Cream/tree/main/AutoFormer">code</a> is now released. Reported by <a href="https://ai-scholar.tech/en/articles/transformer/AutoFormer">1</a>, <a href="
                    https://www.163.com/dy/article/GFR3FGAB05118HA4.html">2</a>, <a href="
                    https://www.leiphone.com/category/academic/S4mNLoLQL06YlfFC.html">3</a>, <a href="
                    https://mp.weixin.qq.com/s?src=11&timestamp=1629727482&ver=3270&signature=-tEiEiNIEkGbS4DBcOlU*mpi*2r3zA3HK2M1ymMiyhn3QOVXyW7VUDxXxa0BDXBxrmVN5uc3M449diFDZQ7u88e8EH2QVWsVGH*fewoQpK3vwM3XSNsgFumvsBxvx0RU&new=1">4</a> ...
                    </font>
                    </li>                

                    <li>
                    <font face="Arial" size="3.5" color="black"> 
                    <font face="Arial" size="3.5">08/2021</font> - Invited as a senior program committee (SPC) member for <a href="https://aaai.org/Conferences/AAAI-22/aaai22call">AAAI 2022</a>.
                    </font>
                    </li>

                    <li>
                    <font face="Arial" size="3.5" color="black"> 
                    <font face="Arial" size="3.5">07/2021</font> - Four papers accepted by <a href="http://iccv2021.thecvf.com">ICCV 2021</a>.
                    </font>
                    </li>

                    <li>
                    <font face="Arial" size="3.5" color="black"> 
                    <font face="Arial" size="3.5">07/2021</font> - Our image relative position encoding <a href="https://arxiv.org/abs/2107.00651">iRPE</a> accepted by ICCV 2021, <a href="https://github.com/microsoft/AutoML/tree/main/iRPE">Code</a> and <a href="https://mp.weixin.qq.com/s/TWpOOT79LLSWpq5_DB-ykQ">Blog</a>.
                    </font>
                    </li>

                    <li>
                    <font face="Arial" size="3.5" color="black"> 
                    <face="Arial" size="3.5">07/2021 - Our work on NAS vision transformer <a href="https://arxiv.org/abs/2107.00651">AutoFormer</a> is available on <a href="https://arxiv.org/abs/2107.00651">ArXiv</a>.
                    </font>
                    </li>

                	<li>
                    <font face="Arial" size="3.5" color="black"> 
                    <font face="Arial" size="3.5">04/2021</font> - Appointed as Area Chair of <a href="https://2021.acmmm.org/">ACM Multimedia 2021</a>.
                    </font>
                    </li>

                	<li>
                    <font face="Arial" size="3.5" color="black"> 
                    <font face="Arial" size="3.5">04/2021</font> - A simple spatio-temporal transformer tracker <a href=" https://arxiv.org/abs/2103.17154">STARK</a> is released. <a href="https://github.com/researchmm/Stark">Code</a> and <a href="https://www.msra.cn/zh-cn/news/features/transformer-in-vision">Blog</a>. 
                    </font>
                    </li>

                    <li>
                    <font face="Arial" size="3.5" color="black"> 
                    <font face="Arial" size="3.5">03/2021</font> - Two works on NAS (<a href="https://arxiv.org/abs/2104.00597">EnsembleNAS</a> and <a href="https://github.com/researchmm/LightTrack"> LightTrack</a>) accepted by <a href="http://cvpr2021.thecvf.com/">CVPR 2021</a>.
                    </font>
                    </li>

                    <li>
                    <font face="Arial" size="3.5" color="black"> 
                    <font face="Arial" size="3.5">12/2020</font> - <a href="https://papers.nips.cc/paper/2020/file/d072677d210ac4c03ba046120f0802ec-Paper.pdf">CreamNAS</a> is integrated into Microsoft <a href="https://github.com/microsoft/nni/blob/master/docs/en_US/NAS/Cream.rst">NNI 2.0</a> AutoML platform. 
                    </font>
                    </li>

                    <li>
                    <font face="Arial" size="3.5" color="black"> 
                    <font face="Arial" size="3.5">11/2020</font> - Our <a href="https://papers.nips.cc/paper/2020/file/d072677d210ac4c03ba046120f0802ec-Paper.pdf">Cream</a> NAS work was accepted by NeurIPS2020. <a href="https://github.com/microsoft/Cream">Code</a> and <a https://www.msra.cn/zh-cn/news/features/neurips-2020-distilling-prioritized-paths-for-one-shot-nas> Blog</a>.
                    </font>
                    </li>

                	<li>
                    <font face="Arial" size="3.5" color="black"> 
                    <font face="Arial" size="3.5">07/2020</font> - <a href="https://arxiv.org/abs/2006.10721">Ocean</a> is accepted by ECCV2020. <a href="https://github.com/researchmm/TracKit">Code</a> is available.
                    </font>
                    </li>

                    
                    <li>    
                    <font face="Arial" size="3.5" color="black">
                    <font face="Arial" size="3.5">06/2020</font> - <a href="https://arxiv.org/abs/2006.10724"> CDARTS</a> has integrated into Microsoft <a href="https://github.com/microsoft/nni">NNI</a> AutoML platform.  
                    </font>

                	<li>	
                    <font face="Arial" size="3.5" color="black">
                    <font face="Arial" size="3.5">06/2020</font> - We released a cyclic differentiable neural architecture search algorithm, <a href="https://arxiv.org/abs/2006.10724">CDARTS</a> and <a href="https://github.com/researchmm/CDARTS">Code</a>. 
                    </font>

                    <li>
                    <font face="Arial" size="3.5" color="black"> 
                    <font face="Arial" size="3.5">06/2020</font> - We released the object-aware anchor-free tracking algorithm (Ocean), <a href="https://arxiv.org/abs/2006.10721">arXiv</a> and <a href="https://github.com/researchmm/TracKit">Code</a>. 
                    </font>
                    </li>
                    

                    <li>
                    <font face="Arial" size="3.5" color="black"> 
                    04/2020 - A simple transductive video object segmentation approach, dubbed <a href="https://arxiv.org/pdf/2004.07193.pdf">TVOS</a>, was accepted by CVPR2020. <a href="https://github.com/microsoft/transductive-vos.pytorch">Code</a> was released!
                    </font>
                    </li>

                    <li>
                    <font face="Arial" size="3.5" color="black"> 
                    10/2019 - A coauthor paper on video moment localization, dubbed <a href="https://arxiv.org/pdf/1912.03590.pdf">2D-TAN</a>, was accepted by AAAI2020. <a href="https://github.com/microsoft/2D-TAN">Code</a> and <a href="https://www.msra.cn/zh-cn/news/features/aaai-2020-2d-tan">Blog </a>. 
                    </font>
                    </li>

                    <li>
                    <font face="Arial" size="3.5" color="black"> 
                    09/2019 - Our team achieved <a href="http://hacs.csail.mit.edu/challenge2019.html"> Rank #1 </a> in HACS Temporal Action Localization Challenge at ICCV2019 workshop. 
                    </font>
                    </li>


                    <li>
                    <font face="Arial" size="3.5" color="black"> 
                    07/2019 - Our team achieved one <a href="http://www.votchallenge.net/vot2019/program.html"> Winner</a> and two Runner-ups in VOT2019 challenges. <a href="https://github.com/researchmm/SiamDW"> Code</a> was released.
                    </font>
                    </li>

                    <li>
                    <font face="Arial" size="3.5" color="black"> 
                    03/2019 - Our first tracking paper, dubbed <a href="http://openaccess.thecvf.com/content_CVPR_2019/html/Zhang_Deeper_and_Wider_Siamese_Networks_for_Real-Time_Visual_Tracking_CVPR_2019_paper.html">SiamDW</a>, was accepted by CVPR2019 as an Oral. <a href="https://github.com/researchmm/SiamDW">Code</a> is available.
                    </font>
                    </li>

                    </ul>
                </div>   

  
  
    
    <footer >
            <br>
            <br>
            <div align='center'> Copyright &copy; 2019-2023 HOUWEN PENG</div>
            <!--<div align='center'> &nbsp; <a href="https://www.hit-counts.com/"><img alt="HTML Counter" border="0" src="http://www.hit-counts.com/counter.php?t=MTQ0NjY3Nw=="></a> </div>-->
    </footer>
    

            
    <!-- ENDS MAIN -->  
  


    
</div></div></body></html>
